{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog or Cat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a simple convolutional neural network to distinguish between images of dogs and cats. It can be run using Google Colab (to speed up training) or locally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some packages to use\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#For the model \n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#To see our directory\n",
    "import os, datetime\n",
    "import random\n",
    "import gc   #Gabage collector for cleaning deleted data from memory\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name() #to test whether we're using a gpu\n",
    "\n",
    "#If running on Google Colab with data in Google Drive, enable the following \n",
    "if False:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  root_path = 'drive/My Drive/DogVsCat'\n",
    "else:\n",
    "    root_path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_im = 500   # Specify the number of images to load of each category\n",
    "\n",
    "train_dir = os.path.join(root_path,'data/train')\n",
    "test_dir = os.path.join(root_path,'data/test')\n",
    "\n",
    "train_dogs = [f'{train_dir}/{i}' for i in os.listdir(train_dir) if 'dog' in i]  #get dog images\n",
    "train_cats = [f'{train_dir}/{i}' for i in os.listdir(train_dir) if 'cat' in i]  #get cat images\n",
    "\n",
    "test_imgs = [f'{test_dir}/{i}' for i in os.listdir(test_dir)] #get test images\n",
    "\n",
    "train_imgs = train_dogs[:num_im] + train_cats[:num_im]  # slice the dataset and use 2000 in each class\n",
    "random.shuffle(train_imgs)  # shuffle it randomly\n",
    "\n",
    "#Clear list that are useless\n",
    "del train_dogs\n",
    "del train_cats\n",
    "gc.collect()   #collect garbage to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets view some of the pics\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(cv2.imread(train_imgs[i], cv2.IMREAD_COLOR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images all need to have consistent sizes in order to feed in to the neural network.\n",
    "\n",
    "This function will resize the images so that they're all 150x150 pixels, and also extract the \"dog\" or \"cat\" text from the filename to use as a label for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets declare our image dimensions\n",
    "#we are using coloured images. \n",
    "nrows = 150\n",
    "ncolumns = 150\n",
    "channels = 3  #change to 1 if you want to use grayscale image\n",
    "\n",
    "\n",
    "#A function to read and process the images to an acceptable format for our model\n",
    "def read_and_process_image(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        X is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    X = [] # images\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))  #Read the image\n",
    "        #get the labels\n",
    "        if 'dog' in image:\n",
    "            y.append(1)\n",
    "        elif 'cat' in image:\n",
    "            y.append(0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the train and label data\n",
    "X, y = read_and_process_image(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets view some of the pics now that they've been resized\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the list of images in to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_imgs\n",
    "gc.collect()\n",
    "\n",
    "#Convert list to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "#Lets plot the labels to be sure we just have two balanced class\n",
    "sns.countplot(y)\n",
    "plt.title('Labels for Cats and Dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train images is:\", X.shape)\n",
    "print(\"Shape of labels is:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split some images off from the train set to validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets split the data into train and test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of validation images is:\", X_val.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)\n",
    "print(\"Shape of labels is:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear memory\n",
    "del X\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "#get the length of the train and validation data\n",
    "ntrain = len(X_train)\n",
    "nval = len(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot's of parameters need to be chosen and optimised when training a neural network. Some of the most important ones are the number of epochs, batch size, learning rate and the amount of data augmentation.\n",
    "\n",
    "**Number of epochs:**\n",
    "> Number of times the network will see the entire training set. One epoch is an entire pass over the training set. If this is too large the network will overfit to the training set, if it's too small the network will not reach optimal performance. Look in to \"early stopping\" if you want to optimise this. \n",
    "\n",
    "**Batch size**\n",
    " > The number of images that will be passed through to the network at one time. This should be a power of 2 (e.g. 4,8,16,32,64...) for more efficient GPU training. The number of batches that make up one epoch = size of training set / batch size. The size of a batch must be more than or equal to one and less than or equal to the number of samples in the training dataset. Too small leads to noisier training, too large lessens the ability of the network to generalise (and also is a strain on memory). 32 or 64 are good sizes.\n",
    "\n",
    "**Learning rate**\n",
    "> Controls how much to change the model in response to the estimated error each time the model weights are updated. Since model weights are updated after each batch, the learning rate should be optimised with the batch size. When starting off, err on the side of smaller. \n",
    "\n",
    "**Augmentation**\n",
    "> This is an easy way of artificially increasing the size of your dataset. Since CNN's have HEAPS of parameters that need to be trained, they need a proportional amount of data to train them. If you can't get more data (and labels) augmentation is the next best thing. If you can do it, you should! Examples of image augmentation include: zooming in/out, rotating the image, flipping the image, adding noise, shifting the image. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where we set these parameters\n",
    "\n",
    "num_epoch = 200 \n",
    "batch_size = 32 \n",
    "learning_rate = 1e-2 \n",
    "aug_flag=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Code\n",
    "* This is a pretty small CNN, it has 4 x 2D convolutional layers, each with 3 x 3 kernels, and increasing number of features in each layer. \n",
    "* The convolutional layers are separated by \"max pooling\" layers, which halve the size of the data at that layer.\n",
    "* The output is then \"flattened\" in to essentially a 1 x 6272 feature vector that represents the entire image.\n",
    "* This is followed by 2 normal layers (\"dense\" layers) that distill the features to a single number\n",
    "* This number decides whether the image is a cat or dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))  #Dropout for regularization\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see our model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll use the RMSprop optimizer with a learning rate of 0.0001\n",
    "#We'll use binary_crossentropy loss because its a binary classification\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create the augmentation configuration\n",
    "#This helps prevent overfitting, since we are using a small dataset\n",
    "if aug_flag:\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,)\n",
    "else:\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255)  #Scale the image between 0 and 1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale\n",
    "\n",
    "#Create the image generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at what augmentation does to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tmp,y_tmp=next(train_generator)\"\"\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "im_tmp = train_datagen.flow(X_train[:1], y_train[:1], batch_size=1) #setup a temporary generator with just one image\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(next(im_tmp)[0][0,:])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard let's us investigate the performance of the network as it trains. It also let's us compare different networks and identify issues with the training. This is done through a \"callback\". Callbacks are run after each batch, and there are a lot that can be applied quite easily through Keras.\n",
    "\n",
    "This tensorboard callback will save logs during each training, named according to the parameters we set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "log_dir= os.path.join(root_path, 'logs', f'bs{batch_size}_lr{learning_rate}_aug{aug_flag}_sz{ntrain}')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The training part\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=ntrain // batch_size,\n",
    "                              epochs=num_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=nval // batch_size, \n",
    "                              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "if False:\n",
    "  model.save_weights(os.path.join(root_path,'model_wieghts.h5'))\n",
    "  model.save(os.path.join(root_path,'model_keras.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot the train and val curve\n",
    "#get the details form the history object\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how it goes on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets predict on the first 10 Images of the test set\n",
    "X_test, y_test = read_and_process_image(test_imgs[0:10]) #Y_test in this case will be empty.\n",
    "x = np.array(X_test)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "i = 0\n",
    "text_labels = []\n",
    "plt.figure(figsize=(30,20))\n",
    "for batch in test_datagen.flow(x, batch_size=1):\n",
    "    pred = model.predict(batch)\n",
    "    if pred > 0.5:\n",
    "        text_labels.append('dog')\n",
    "    else:\n",
    "        text_labels.append('cat')\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.title('This is a ' + text_labels[i])\n",
    "    imgplot = plt.imshow(batch[0])\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare the different models using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir f'{root_path}logs'\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
